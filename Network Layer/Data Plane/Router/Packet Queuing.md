-----
### 출력 포트 처리
-----
1. 출력 포트 메모리에 저장된 패킷을 가져와 출력 링크를 통해 전송
2. 전송을 위한 패킷 선택(즉, 스케줄링) 및 큐 제거, 필요한 링크 계층 및 물리 계층 전송 기능을 수행하는 것 포함

-----
### 큐잉 발생
-----
<div align="center">
<img src="https://github.com/user-attachments/assets/a338243b-c7fc-473b-83f6-f7c03be23dde">
</div>

1. 패킷 큐는 입력 포트와 출력 포트 모두에서 형성 가능
   - 큐의 위치와 범위(입력 포트 큐 또는 출력 포트 큐)는 트래픽 로드, 스위치 구조의 상대 속도 및 라인 속도에 따라 달라짐
   - 큐가 커지면 라우터는 메모리가 결국 소모될 수 있고 도착하는 패킷을 저장할 수 있는 메모리가 없을 때 패킷 손실(Packet Loss)이 발생
   - 즉, 패킷이 네트워크 내에서 손실되거나 라우터에서 감소 : 라우터 내 패킷이 실제로 삭제되고 손실되는 큐에 있음

2. 입력 및 출력 라인의 속도(전송률)는 모두 초당 $R_{line}$ 패킷으로 동일한 전송을 갖고 있고, N개의 입력 포트와 N개의 출력 포트가 있다고 가정
   - 단순화를 위해 모든 패킷이 고정 길이가 같고 패킷이 동기식으로 입력 포트에 도착한다고 가정
   - 즉, 임의의 링크 상 패킷을 송신하는 시간은 임의의 링크상에서 패킷을 수신하는 시간과 동일하고, 그러한 시간 간격 동안 0 또는 하나의 패킷이 입력 링크상 도착할 수 있음
   - 패킷이 입력 포트에서 출력 포트로 이동할 수 있는 속도로 스위치 구조 전송률 $R_{switch}$로 정의
   - 만약, $R_{switch}$가 $R_{line}$ 보다 N배 빠르다면, 입력 포트에서 발생하는 큐잉은 무시 가능 (이는 최악의 경우에도 모든 N 입력 라인이 패킷들을 수신하고 모든 패킷이 같은 출력 포트에 전달되는 곳에서 N 패킷들(입력 포트당 1개의 패킷)의 배치 작업은 다음 배치 작업이 도착하기 전 스위치 구조를 통해 삭제될 수 있기 때문임)

-----
### 입력 큐잉
-----
1. 지연 없이 구조를 통해 도착하는 모든 패킷을 전송하기에 스위치 구조가 입력 라인 속도에 비해 충분히 빠르지 않은 경우
   - 패킷이 스위치 구조를 통해 출력 포트로 전송되기 위해 차례를 기다려야 함
   - 크로스바 스위치 구조로 가정
     + 모든 링크 속도는 같음
     + 입력 링크가 패킷을 받는 것과 같은 속도로 하나의 패킷을 입력 포트에서 주어진 출력 포트로 전달
     + FCFS 방식으로 패킷은 입력 큐에서 출력 큐로 이동됨
     + 출력 포트가 다르다면 여러 패킷이 병렬로 전달될 수 있지만, 두 패킷이 같은 출력 큐로 향한다면 이 중 한 패킷은 차단되고 입력 큐에서 기다려야 함
     + 즉, 스위치 구조는 한 번에 하나의 패킷만 지정된 출력 포트로 전송 가능

2. 입력 큐 앞쪽에 있는 2개의 패킷이 동일한 오른쪽 상단의 출력 포트로 보내지는 예
<div align="center">
<img src="https://github.com/user-attachments/assets/b85bfbe3-0bbc-4917-8662-20e77b61a203">
</div>

   - 스위치 구조가 왼쪽 상단 큐의 앞쪽으로 패킷을 전송한다고 가정
   - 이 경우, 왼쪽 하단 큐에 짙은 색으로 처리된 두 번쨰 패킷은 대기해야 함
   - 아래쪽 밝은 패킷은 이동하려는 출력 링크(패킷의 목적지)가 경쟁이 없는 상태이지만 바로 앞 검정 패킷 때문에 기다려야 함
   - 이 현상은 입력 대기 중인 스위치에서의 HOL(Head-Of-the-Line) 차단(블로킹)이라고 하며, 라인의 앞쪽에서 다른 패킷이 막고 있으므로 입력 큐에서 대기 중인 패킷은 사용할 출력 포트가 사용 중이지 않아도 스위치 구조를 통해 전송되기 위해 기다려야 함
   - 입력 링크에서 패킷 도착 속도가 용량의 58%가 되면, HOL 차단 때문에 입력 큐가 무한정 길이로 증가하여 중요 패킷이 손실되는 패킷 손실이 증가

3. 출력 큐잉의 예
   - 스위치 출력 포트에서도 큐잉이 발생할 수 있는데, 먼저 R 스위치가 다시 $R_{line}$보다 N배 빠르며, N개의 입력 포트 각각에 도착하는 패킷이 동일한 출력 포트로 향하는 것으로 가정
     + 이 경우, 출력 링크에 단일 패킷을 보내는데 걸리는 시간에 N개의 새로운 패킷이 출력 포트(N개의 입력 포트 각각 하나씩)에 도착
     + 출력 포트는 시간 단위(패킷 전송 시간)에 단일 패킷만 전송할 수 있으므로 N개의 도착 패킷은 출력 링크를 통한 전송 큐에서 대기해야 함
     + 그러면, 대기 중인 N개의 패킷 중에서 하나를 전송할 때 다시 N개의 새로운 패킷이 도착할 수 있으므로, 스위치 구조가 포트 라인 속도보다 N배 빠른 경우에도 패킷 큐잉이 출력 포트에서 발생 가능
     + 결국, 대기 중인 패킷 수가 출력 포트에서 사용 가능한 메모리를 다 소모할 만큼 충분히 많아질 수 있음

   - 들어오는 패킷을 저장할 메모리가 충분하지 않을 때 도착한 패킷을 삭제(Drop-tail 정책)하거나 이미 대기 중인 하나 이상의 패킷을 제거해 새로 도착한 패킷을 저장하기 위한 공간을 확보해야 함
   - 어떤 경우에는 버퍼가 가득 차기 전 패킷을 삭제(또는 헤더 마킹)하여 송신자에게 혼잡 신호를 제공하는 것이 바람직할 수 있음
   - 또는, 명시적 혼잡 알림(ECN) 비트 사용, AQM(Active Queue Management) 알고리즘으로 알려진 많은 패킷 삭제와 패킷 마킹 정책이 제안되거나 분석되고 있음
   - 가장 폭넓게 연구되고 구현된 AQM 알고리즘 중 하나는 RED(Random Early Detection)이며, 좀 더 최근 AQM 정책에는 PIE(Proportional Integral Controller Enhanced) 및 CoDel이 포함

   - 출력 포트 큐잉
<div align="center">
<img src="https://github.com/user-attachments/assets/0b0fae78-f4cb-4222-99f1-1e0bbca4e8a1">
</div>

   - 시각 t에서 패킷은 각 입력 포트에 도달하고 각 포트는 맨 앞의 출력 포트로 향함
   - 동일한 라인 속도를 가지고, 라인 속도의 3배(즉, 패킷을 수신 또는 전송하는데 필요 시간)로 동작하는 것으로 가정
   - 기존의 패킷 3개가 모두 출력 포트로 전송되어 대기 중
   - 이 3개 패킷 중 하나는 다음 번 출력 라인을 통해 전송될 것
   - 2개의 새로운 패킷이 수신 측에 도착했고, 이 패킷 중 하나는 맨 앞 출력 포트로 전송
   - 이러한 큐잉의 결과는 출력 포트의 패킷 스케줄러(Packet Schedular)가 전송 대기 중인 패킷 중 하나의 패킷을 선택해야 함

-----
### 버퍼 크기
-----
1. 버퍼 크기에 대한 규칙
   - 링크 용량이 C이고, 버퍼링의 양(B)은 평균 왕복 시간(RTT, 250ms)과 같아야 함
   - 따라서, RTT가 250ms인 10Gbps 링크는 버퍼들의 B = RTT * C = 2.5Gb와 같은 버퍼의 양 필요
   - 결과적으로 상대적으로 작은 양의 TCP 흐름에 대한 큐잉 분석을 기반을 둠
   - 최근에는 독립적인 TCP 흐름(N)이 링크를 통과할 때, 필요한 버퍼링은 $B = RTT * (C / \sqrt{N})$로 제안
     + 일반적으로 거대한 백본 라우터 링크를 통과하는 많은 수의 TCP 흐름이 있는 코어 네트워크에서, N 값이 커질 수 있으며 필요한 버퍼 크기가 감소가 상당함이 두드러짐

2. 버퍼링이 클수록 라우터가 패킷 도착 속도의 큰 변동을 흡수하여 라우터의 패킷 손실률을 감소시킬 수 있으므로 버퍼링이 더 낫다고 생각할 수 있지만, 버퍼가 클수록 큐잉 지연이 길어진다고 생각하는 것이 좋음
   - 증가된 RTT는 또한 TCP 송신자의 초기 혼잡 또는 패킷 손실에 대한 응답을 떨어트림
   - 버퍼링은 트래픽의 단기 통계 변동을 흡수하는데 사용될 수 있지만 지연과 그에 따른 우려를 증가시킬 수 있음

3. 많은 독립적인 송신자들이 혼잡한 링크에서 대역폭과 버퍼를 놓고 경쟁하고 있다고 암시적 가정
<div align="center">
<img src="https://github.com/user-attachments/assets/e69c8047-71cf-4f62-b41b-9abe3fab1bc3">
</div>

   - TCP 세그먼트를 원격 게임 서버로 보내는 홈 라우터에 대한 설명
   - 게이머의 TCP 세그먼트를 포함하는 패킷을 전송하는데 20ms 소요, 큐잉 지연은 무시해도 될 정도라고 가정
   - 게임 서버 경로의 다른 곳에서 지연되며 RTT는 200ms
   - t = 0에서 25개 버킷 버스트가 큐에 도착한다고 가정
     + 대기 중인 패키들 중 하나는 20ms마다 한 번 씩 전송되므로, 21번째 패킷이 전송되고 있는 것처럼 t = 200ms에서 첫 번째 ACK 도착
     + 이 ACK 도착은 TCP 송신자가 다른 패킷을 보내게 하며, 대기하게 됨
     + 홈 라우터 송신 링크 t = 220ms에서 다음 ACK가 도착하고, 또 다른 ACK가 도착
     + TCP 세그먼트는 게이머에 의해 해제되며, 22번째 패킷은 전송되는 큐에 놓임
   - ACK 클록은 대기 중인 패킷이 있을 때마다 새 패킷이 큐에 도착하게 되고, 전송되어 홈 라우터의 송신 링크에서 큐 크기가 항상 5패킷이 됨
   - 즉, 종단 간 파이프는 꽉 찼지만(매 20ms 병목률로 한 패킷의 경로의 목적지까지 전송하는 것) 큐잉 지연의 양은 일정하고 지속적
   - 그 결과, 홈 네트워크에 다른 트래픽이 존재하지 않는 경우에도 지연이 지속적으로 지나치게 긴 이유

4. 지속적 버퍼링으로 인한 긴 지연에 대한 이 시나리오를 버퍼블로트(BufferBloat, 패킷의 과도한 버퍼링으로 인해 생기는 패킷 교환 네트워크의 높은 대기 시간 원인)
   - 처리량뿐만 아니라 최소 지연도 중요하며, 네트워크 가장자리와 네트워크 내 큐에서 송신자가 간의 상호작용이 실제로 복잡하고 미묘함을 보여줌
   - 이를 방지하기 위해 특정 AQM 메커니즘을 추가해 대량 처리 성능 보존

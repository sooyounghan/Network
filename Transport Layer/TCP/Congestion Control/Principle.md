-----
### 혼잡의 원인과 비용
-----
1. 시나리오 1 : 2개의 송신자와 무한 버퍼를 갖는 하나의 라우터
   - 두 호스트 A와 B가 각 출발지와 목적지 사이에 단일 홉을 공유하는 연결을 가진다고 가정
<div align="center">
<img src="https://github.com/user-attachments/assets/8d6b71f5-05ab-4fae-adc5-11f96c17569c">
</div>

   - 호스트 A의 애플리케이션이 $λ_{in}$바이트/초의 평균 전송률로 연결 (소켓을 통해 트랜스포트 계층 프로토콜로 데이터를 넘겨주는 것) 상으로 데이터를 보내고 있다고 가정
     + 각 데이터 단위가 소켓으로 한 번만 전송된다는 점에서 원본 데이터이며, 하위의 트랜스포트 계층 프로토콜은 단순하게 데이터를 캡슐화하고 전송
     + 오류 복구(재전송 등), 흐름 제어 또는 혼잡 제어를 수행하지 않음
     + 트랜스포트 계층과 하위 계층에서 헤더 정보의 추가로 인한 부가적인 오버헤드를 무시하면, 호스트 A가 라우터에게 제공하는 속도는 $λ_{in}$ 바이트/초
     + 호스트 B도 비슷한 방식으로 동작하며, $λ_{in}$바이트/초의 전송률로 데이터를 전송한다고 가정
   - 호스트 A와 호스트 B가 전송되는 패킷은 라우터와 용량 R의 공류 출력 링크를 통과하며, 라우터는 패킷 도착률이 출력 링크의 용량을 초과하여 입력되는 패킷들을 저장하는 버퍼를 가지고 있음
   - 여기서 라우터는 무제한의 버퍼 공간을 갖는다고 가정
   - 호스트 A의 연결 성능을 나타낸 것
<div align="center">
<img src="https://github.com/user-attachments/assets/12721b88-2609-4d9d-9305-f4796231f772">
</div>

   - 왼쪽 그래프 : 연결 전송률의 함수로 연결당 처리량(Per-Connection Throughtput, 수신자 측에서의 초당 바이트 수)을 그린 것
     + 0과 R/2 사이의 전송률에 대해 수신자 측의 처리량은 송신자 전송률과 같음
     + 송신자가 보내는 모든 데이터는 유한한 지연으로 수신자에게 수신
     + 하지만 전송률이 R/2 이상일 때, 처리량은 단지 R/2에 불과하며, 이러한 상한은 두 연결 사이 링크 용량 공유 결과
     + 링크는 안정 상태에서 R/2를 초과해서 패킷을 수신자에게 전달할 수 없으며, 호스트 A와 B가 전송률이 아무리 높게 설정되었다하더라도, 각 R/2보다 높은 처리량 얻을 수 없음
     + R/2 연결 당 처리량을 얻는 것은 목적지에 패킷을 전달하는 데 링크를 최대로 활용하므로 좋은 현상
   - 오른쪽 그래프 : 링크 용량 근처에서 동작 결과
     + 전송률이 R/2에 근접했을 때, 평균 지연은 점점 커짐
     + 전송률이 R/2를 초과할 때, 라우터 안에 큐잉된 패킷의 평균 개수는 제한되지 않고, 출발지와 목적지 사이 평균 지연이 무제한이 됨
     + 따라서, R 근처에 전체 처리량에서 동작하는 것은 처리량 관점에서 이상적이지만, 지연 관점에서는 이상적이지 않음
   - 패킷 도착률이 링크 용량에 근접함에 따라 큐잉 지연이 커짐

2. 시나리오 2 : 2개의 송신자, 유한 버퍼를 가진 하나의 라우터
<div align="center">
<img src="https://github.com/user-attachments/assets/45004fc8-3743-4565-b5df-e31fd69cb481">
</div>

  - 라우터 버퍼의 양이 유한하다고 가정 : 버퍼가 가득찼을 때 도착하는 패킷들은 버려짐
  - 각 연결은 신뢰적으라고 가정 : 트랜스포트 계층 세그먼트를 포함하는 패킷이 라우터에서 버려지면, 결국 송신자에 의해 재전송될 것
  - 패킷이 재전송될 수 있으므로, 송신율이라는 단어의 의미가 중요
    + 애플리케이션이 원래 데이터를 소켓으로 보내는 송신율을 $λ_{in}$ 바이트/초로 표기
    + 네트워크 안으로 세그먼트(원래 데이터와 재전송 데이터 포함)를 송신하는 트랜스포트 계층에서의 송신율 $λ′_{in}$ 바이트/초로 표시하고, 네트워크에 제공된 부하(Offered Load)

<div align="center">
<img src="https://github.com/user-attachments/assets/48e5790b-6eec-424f-b682-fb3dfd449171">
</div>

   - 호스트 A가 라우터에 있는 버퍼가 비어있는지 아닌지 알 수 있고, 버퍼가 비어있을 때만 송신할 수 있는 비현실적인 경우 고려 : $λ_{in}$와 $λ`_{in}$은 같으므로 어떤 손실도 발생하지 않고, 연결의 처리량은 $λ_{in}$과 같음

     + 처리율 관점에서 보면 송신된 모든 것을 수신되기 때문에, 성능은 이상적이지만 평균 호스트 송신율은 R/2를 초과할 수 없음
   - 패킷이 확실히 손실된 것을 알았을 때 송신자가 재전송하는 현실적인 경우 : 송신하는 호스트가 확인응답 하지 않는 패킷이 사실상 손실되었다는 것을 확신하기에 충분히 큰 타임아웃 설정
     + 제공된 부하 $λ′_{in}$(최초의 데이터 전송과 재전송 합의 속도)이 R/2일 경우, 제공된 부하의 값에서 수신자 애플리케이션으로 전달되는 데이터 전송률은 R/3 (2/3는 원래의 데이터, 1/3은 재전송 데이터)
     + 즉, 송신자는 버퍼 오버플로우 때문에 버려진 패킷을 재전송하기 때문에 네트워크 또다른 비용 발생

   - 송신자에게 너무 일찍 타임 아웃되어 패킷이 손실되지 않았지만, 큐에서 지연되고 있는 패킷을 재전송하는 경우 : 원래 데이터 패킷과 재전송 패킷 둘 다 수신자에게 도착
     + 물론, 수신자는 단지 하나의 패킷 복사본을 필요하므로 재전송 패킷은 버림
     + 수신작가 이미 패킷의 원래 복사본을 수신했을 때, 라우터에서 원래 패킷의 재전송된 복사본을 전달하는 작업은 낭비
     + 라우터는 다른 패킷을 송신하기 위해 링크 전송 용량을 사용하는 거이 좋음
     + 즉, 커다란 지연으로 인한 송신자의 불필요한 재전송은 라우터가 불필요한 복사본들을 전송하는데 링크 대역포을 사용하는 원이이 됨
     + 각 패킷이 라우터에 의해 두 번씩 전달(평균)된다고 가정 : 각 패킷이 두 번씩 전달되므로 제공된 부하가 R/2일 때, 처리량은 R/4의 점선 값을 가짐

3. 시나리오 3 : 4개의 송신자와 유한 버퍼를 갖는 라우터, 멀티홉 경로
<div align="center">
<img src="https://github.com/user-attachments/assets/0ec12345-c96f-4e6e-8945-c0e1cc8b75da">
</div>

   - 4개의 호스트는 겹쳐지는 2홉 경로를 통해 패킷 전송
   - 호스트가 안정적 데이터 전송 서비스를 실행하기 위해 타임아웃/재전송 메커니즘을 사용한다고 가정
   - 모든 호스트는 $λ_{in}$의 동일한 값을 갖고, 모든 라우터 링크는 R 바이트/초 용량을 갖는다고 가정
   - 라우터 R1과 R2를 지기나는 호스트 A에서 호스트 C까지의 연결을 고려
     + 라우터 R1 : 호스트 D에서 호스트 B로 연결을 공유
     + 라우터 R2 : 호스트 B에서 호스트 D로 연결을 공유
   - $λ_{in}$의 극히 작은 값에 대해 버퍼 오버플로우는 거의 발생하지 않고, 제공된 부하가 거의 같음
   - $λ_{in}$의 약간 큰 값에 대해 원래 데이터가 네트워크로 전송되고, 목적지에 전달되고, 오버플로가 거의 발생하지 않으므로, 해당하는 처리량은 약간 커짐
   - 그러므로 $λ_{in}$이 작은 값일 때, $λ_{in}$의 증가는 $λ_{out}$의 증가를 가져옴
   - $λ_{in}$ 값이 매우 큰 경우
     + 라우터 R2 : 라우터 R2에 도착하는 (R1에서 전달된 후 R2에 도착하는) 호스트 A에서 호스트 C로의 트래픽은 $λ_{in}$의 값에 관계 없이 R1에서 R2까지 링크 용량, 최대 R인 도착률을 가질 수 있음
     + 만약, $λ`_{in}$이 모든 연결(호스트 B와 호스트 D 연결 포함)에 대해 매우 크다면, R2의 호스트 B에서 호스트 D로의 트래픽 도착률은 호스트 A에서 호스트 C로의 트래픽 도착률보다 클 수 있음
     + 따라서, A ~ C와 B ~ D 트래픽은 버퍼 공간을 R2 라우터에 경쟁 : R2를 성공적으로 통과하는 A ~ C 트래픽의 양은 B ~ D에서 제공된 부하가 크면 클수록 더 작아짐
     + 제공된 부하가 무한대에 가까워지면, R2의 빈 버퍼는 즉시 B ~ D 패킷으로 채워지고, R2에서 A ~ C에서 연결 처리량은 0 : 즉, 트래픽이 많은 경우 A ~ C의 종단간 처리율이 0이 되는 것을 의미
     + 즉, 제공된 부하와 처리량 간 트레이드-오프 발생
<div align="center">
<img src="https://github.com/user-attachments/assets/621d2c34-ee48-4b99-b76b-b8476ef9308f">
</div>

   - 과도한 트래픽 시나리오에서 패킷이 두 번째 홉 라우터에서 버려질 때 마다, 두 번째 홉 라우터에게 패킷을 전달하는 것은 무용지물임
   - 즉, 혼잡 때문에 패킷을 버려야 하는 또 다른 비용이 발생하며, 패킷이 경로상에서 버려질 때, 버려지는 지점까지 패킷을 전송하는데 사용된 상위 라우터에서 사용된 전송 용량은 낭비 된 것
